{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "17c95720",
   "metadata": {},
   "source": [
    "# **Transformer-Based Chess Engine**\n",
    "\n",
    "### **References**\n",
    "\n",
    "**Noever, D., Ciolino, M., & Kalin, J. (2020).**  \n",
    "*The Chess Transformer: Mastering Play using Generative Language Models.*  \n",
    "[https://arxiv.org/abs/2008.04057](https://arxiv.org/abs/2008.04057)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88175f10",
   "metadata": {},
   "source": [
    "### **Install Dependencies and Import Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "394c0757",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install transformers\n",
    "%pip install gpt-2-simple\n",
    "%pip install bertviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bd4be2c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-11 19:51:35.376899: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-11-11 19:51:36.193086: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-11-11 19:51:42.198944: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from pathlib import Path\n",
    "import random\n",
    "from datasets import load_dataset\n",
    "import gpt_2_simple as gpt2\n",
    "from bertviz import model_view"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de8658bf",
   "metadata": {},
   "source": [
    "### **Preprocessing the Dataset**\n",
    "\n",
    "This step was performed locally, outside of Google Colaboratory. You do not need to execute this step again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2c6d200",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_pgn_file(input_path, output_path):\n",
    "\tif output_path.exists():\n",
    "\t\tprint(f\"‚ö†Ô∏è {output_path.name} already exists, skipping...\")\n",
    "\t\treturn\n",
    "\t\n",
    "\twith open(input_path, encoding=\"utf-8\", errors=\"ignore\") as f:\n",
    "\t\ttext = f.read()\n",
    "\n",
    "\ttext = re.sub(r'\\[.*?\\]', '', text)\n",
    "\n",
    "\ttext = re.sub(r'\\{[^}]*\\}', '', text)\n",
    "\ttext = re.sub(r'\\([^)]*\\)', '', text)\n",
    "\ttext = re.sub(r';[^\\n]*', '', text)\n",
    "\n",
    "\tgames = re.split(r'\\n\\s*\\n', text)\n",
    "\n",
    "\tsaved = 0\n",
    "\n",
    "\twith open(output_path, \"w\", encoding=\"utf-8\") as out:\n",
    "\t\tfor game in games:\n",
    "\t\t\tgame = game.strip()\n",
    "\t\t\tif not game:\n",
    "\t\t\t\tcontinue\n",
    "\n",
    "\t\t\tclean = re.sub(r'\\s+', ' ', game).strip()\n",
    "\n",
    "\t\t\t# clean = re.sub(r'\\b\\d+\\.\\s*', '', clean)\n",
    "\n",
    "\t\t\tclean = re.sub(r'^(.+?)\\s(1-0|0-1|1/2-1/2|\\*)$', r'[Result \\2] \\1', clean)\n",
    "\n",
    "\t\t\tif clean.startswith(\"[Result\"):\n",
    "\t\t\t\tout.write(clean + \"\\n\")\n",
    "\t\t\t\tsaved += 1\n",
    "\n",
    "\tprint(f\"‚úÖ {Path(input_path).name} ‚Üí {Path(output_path).name} ({saved} games saved)\")\n",
    "\n",
    "def process_all_pgn_files(input_directory, output_directory):\n",
    "\tinput_path = Path(input_directory)\n",
    "\toutput_path = Path(output_directory)\n",
    "\n",
    "\toutput_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\tfiles = sorted(input_path.glob(\"*.pgn\"))\n",
    "\t\n",
    "\tfor pgn_file in files:\n",
    "\t\toutput_file = output_path / pgn_file.name.replace(\".pgn\", \".txt\")\n",
    "\t\tpreprocess_pgn_file(pgn_file, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "26a876b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_from_huggingface(dataset_name=\"gabridulol/chess\",\n",
    "                            split=\"train\",\n",
    "                            sample_size=2_701_488,\n",
    "                            seed=42):\n",
    "\n",
    "    print(f\"üì¶ Loading dataset: {dataset_name} (split: {split})\")\n",
    "    ds = load_dataset(dataset_name, split=split, streaming=True)\n",
    "    \n",
    "    random.seed(seed)\n",
    "    reservoir = []\n",
    "    total_seen = 0\n",
    "\n",
    "    print(f\"üéØ Sampling {sample_size:,} games using reservoir sampling...\")\n",
    "\n",
    "    for example in ds:\n",
    "        text = example.get(\"text\") or example.get(\"content\") or str(example)\n",
    "        if not text.strip():\n",
    "            continue\n",
    "\n",
    "        clean_game = \" \".join(text.strip().splitlines())\n",
    "        clean_game = \" \".join(clean_game.split())\n",
    "\n",
    "        total_seen += 1\n",
    "        if len(reservoir) < sample_size:\n",
    "            reservoir.append(clean_game)\n",
    "        else:\n",
    "            j = random.randint(0, total_seen - 1)\n",
    "            if j < sample_size:\n",
    "                reservoir[j] = clean_game\n",
    "\n",
    "        if total_seen % 100000 == 0:\n",
    "            print(f\"‚è≥ Seen {total_seen:,} games...\")\n",
    "\n",
    "    print(f\"\\n‚úÖ Finished. Total seen: {total_seen:,}, sample kept: {len(reservoir):,}\")\n",
    "    \n",
    "    output_path = Path(\"data/chess/lichess-elite-sample/lichess_elite_1st_train.txt\")\n",
    "    output_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(\"\\n\".join(reservoir))\n",
    "\n",
    "    print(f\"üíæ Saved sample to: {output_path.resolve()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4200419",
   "metadata": {},
   "outputs": [],
   "source": [
    "process_all_pgn_files(\n",
    "\t\"data/chess/lichess-elite-database\",\n",
    "\t\"data/chess/lichess-elite-dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e68d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_from_huggingface(\n",
    "    dataset_name=\"data/chess/lichess-elite-dataset\",\n",
    "    split=\"train\",\n",
    "    sample_size=2_701_489,\n",
    "    seed=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bec97ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_games_in_file(file_path):\n",
    "\tcount = 0\n",
    "\twith open(file_path, encoding=\"utf-8\", errors=\"ignore\") as f:\n",
    "\t\tfor line in f:\n",
    "\t\t\tif line.startswith(\"[Result\"):\n",
    "\t\t\t\tcount += 1\n",
    "\treturn count\n",
    "\n",
    "def total_games_in_directory(directory_path):\n",
    "\ttotal = 0\n",
    "\tpath = Path(directory_path)\n",
    "\tfiles = sorted(path.glob(\"*.txt\"))\n",
    "\tfor txt_file in files:\n",
    "\t\ttotal += count_games_in_file(txt_file)\n",
    "\treturn total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "826c8f55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Total games processed: 27014886\n",
      "‚úÖ Total games processed for 1st training: 2701489\n",
      "‚úÖ Total games processed for 2nd training: 27014886\n"
     ]
    }
   ],
   "source": [
    "total = total_games_in_directory(\"data/chess/lichess-elite-dataset\")\n",
    "total_sample = total_games_in_directory(\"data/chess/lichess-elite-sample\")\n",
    "\n",
    "print(f\"‚úÖ Total games processed: {total}\")\n",
    "print(f\"‚úÖ Total games processed for 1st training: {total_sample}\")\n",
    "print(f\"‚úÖ Total games processed for 2nd training: {total}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fcd226c",
   "metadata": {},
   "source": [
    "### **Dataset Overview**\n",
    "\n",
    "The dataset used in this project originates from the [Lichess Elite Database](https://database.nikonoel.fr), which contains chess games played by highly rated players. These games are provided in PGN (Portable Game Notation) format. For this project, the original PGN files were processed and converted into plain text (TXT) format. During preprocessing, all non-essential metadata was removed. The resulting dataset retains only the game result and the sequence of moves expressed in Standard Algebraic Notation (SAN). The processed version of the dataset has been uploaded to [Hugging Face](https://huggingface.co/datasets/gabridulol/chess).\n",
    "\n",
    "### **Dataset Statistics**\n",
    "\n",
    "- **Total games processed:** 27,014,886  \n",
    "- **Total games processed for 1st training:** 10% (2,701,489 games)  \n",
    "- **Total games processed for 2nd training:** 100% (27,014,886 games)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d698d0a",
   "metadata": {},
   "source": [
    "### **The Chess Transformer: Mastering Play using Generative Language Models**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e6b70de",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
